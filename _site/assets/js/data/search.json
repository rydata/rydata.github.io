[
  
  {
    "title": "üÜéüß™ Significance Testing and Statistical Analysis on Taxi Revenue",
    "url": "/posts/stat-analysis-ab-testing/",
    "categories": "Statistics, ABTesting, NYCTLC-Series",
    "tags": "Statistical-Analysis, AB-Testing, Descriptive-Analysis, Python",
    "date": "2023-11-30 00:00:00 +0800",
    





    
    "snippet": "A/B Testing and Statistical Analysis for NYC TLC Fare PaymentEmpire Hotel in NYC Taken from an episode of Gossip Girl. Image Source: thenotsoinnocentsabroad.com/blogProject Overview  A/B Testing sh...",
    "content": "A/B Testing and Statistical Analysis for NYC TLC Fare PaymentEmpire Hotel in NYC Taken from an episode of Gossip Girl. Image Source: thenotsoinnocentsabroad.com/blogProject Overview  A/B Testing showed there is a statistically significant difference in average total payment between cash and credit card payments.  Further analysis shows that the difference might be due to tips.  Another A/B test was conducted without the tips, showing that there is no statistical difference in fare amount, when tips were not accounted.  Using the groupby function, we see that tips are only recorded for credit card payments.  Recommendations were given to incentivize logging of tips.You can access the JUPYTER Notebook IPYNB file here LINKObjectives  NYC TLC requests an analysis of the relationship between fare amount and payment type (cash vs credit card payments) via A/B testing.  Answer: Does different types of payment methods (cash vs credit card) amount to a statistically significant difference in total amount paid?  Provide recommendations to increase revenue for taxis.Project ProcessProject Context  This output is part of a multiple series of outputs for New York City Taxi &amp; Limousine Commission (NYC TLC)  This is a simpler project more focused on gathering insight and analysis than technical process (as compared to our HR Analysis Output).Steps Taken1. Data Exploration  use of .head, .describe, .shape and .groupby for initial analysis on our data.# grouping payment type and total amounttaxi_data.groupby('payment_type')['total_amount'].mean()            payment_type      mean_total_amount                  1 (Credit Card)      17.66              2 (Cash)      13.55              3 (No charge)      13.58              4 (Dispute)      11.24              5 (Unknown)      None        From here we can see that credit card payments are much higher than other types of payments.  This difference might be from random sampling rather than true difference. To investigate this, we can conduct a hypothesis test.2. Hypothesis testing (Round 1)  Our goal is to conduct a two-sample t-test.Identify our null and alternative hypothesis:      H0: There is no difference in the average total fare amount between customers who use credit cards and customers who use cash.        HA: There is a difference in the average total fare amount between customers who use credit cards and customers who use cash.  Choose a significance level:      We choose a 5% significance level for our two-sample t-test. 5% is usually the industry standard and is requested for this project.        We use the ff code block to conduct our test:  Finding the p-value:We use this code block to use scipy stats hypothesis testing library.# conducting our hypothesis testcash = taxi_data[taxi_data['payment_type']==2]['total_amount']credit_card = taxi_data[taxi_data['payment_type']==1]['total_amount']stats.ttest_ind(a=credit_card, b=cash, equal_var=False)Result:Ttest_indResult (statistic=20.34644022783838, pvalue=4.5301445359736376e-91)3. Hypothesis Testing Interpretation (Round 1)Since p-value is significantly smaller than our significance level of 5%, we reject the hypothesis test.We can conclude that there is a statistically significant difference in the average total fare amount credit card vs cash users.Insight!Clarifications has to be made regarding the larger payment for credit cards. It is recommended to look into the following:  First, is there a system bug that causes credit card users to pay more? What may have caused these?  Second, it may be insightful to also look at the average amount of monthly rides for credit card users.          Do credit card users tend to be more ‚Äúpower users‚Äù?      Meaning are they the type of people that spend more on rides or go in longer amount of rides?        Third, is looking at the differences that credit card offers.          Are there any ongoing promotions for credit card users?      Does the hassle free and cashless nature of credit card important to the riders?      Img Source:www.moneymax.phHypothesis Testing Part 2Another comparison is the comparison of the fare amount, which does not include tips, only the base payment.A second round of a/b testing can be looked into to answer this.1. Data Exploration (Round 2)Instead of total amount paid, we use the fare amount to exclude tips.# Grouping payment type and fare amount meantaxi_data.groupby('payment_type')['fare_amount'].mean()            payment_type      mean_total_amount                  1 (Credit Card)      13.43              2 (Cash)      12.21              3 (No charge)      12.19              4 (Dispute)      9.91              5 (Unknown)      None      Removing the tips, we see that there is not as much difference anymore between cash and credit card payments.2. Hypothesis Testing (Round 2)Identify our null and alternative hypothesis:      H0: There is NO difference in the average fare amount (excluding tips) between customers who use credit cards and customers who use cash.        HA: There is A difference in the average fare amount (excluding tips) between customers who use credit cards and customers who use cash.  Choose a significance level:  In this case we retain 5% as our significance levelFinding the p-value:We apply A/B testing with the same code block:cash_fare= taxi_data[taxi_data['payment_type']==2]['fare_amount']credit_card_fare = taxi_data[taxi_data['payment_type']==1]['fare_amount']stats.ttest_ind(a=credit_card_fare, b=cash_fare, equal_var=False)Ttest_indResult(statistic=6.866800855655372, pvalue=6.797387473030518e-12)  Assuming a significance value of 5%, we can see that there is no statically significant difference from cash and payment method.3. Hypothesis Testing Interpretation (Round 2)  Although further analysis on the possible ‚Äòbug‚Äô on higher amount for credit card users, this can be ruled out as there is less difference comparing the mean fare amount for cash and card.We can do another groupby on payment type and tip_amount by its mean.            payment_type      tip_amount                  1 (Credit Card)      2.73              2 (Cash)      0              3 (No charge)      0              4 (Dispute)      0              5 (Unknown)      None        We can observe that no tips are reported during cash payments, only at credit card.Conclusions and RecommendationsImage Source: https://www.blackandwhitecabs.com.auInsight  It can be said that the higher amount for credit cards is due to the fact that tips are not recorded anymore by drivers for cash payments.          It is worth investigating if the company takes a percentage of tips from the riders, disincentiving them from recording tips.        Additionally, it is possible that when paying with credit card, there is an option or requirement within the application to tip, leading to more pay.  Another explanation is that riders do not carry as much cash, so it is easier to pay with credit card for long trips.          In this case, fare amount determines payment type rather than vice versa.      Recommendations  It can be seen that tips are no longer reported on the system on average compared to credit card payment methods.  It is possible for the team to look into methods to further incentivize recording of tips given, through the ff:          Performance Bonuses      Recognition and Rewards      Education and Training      Transparent Communications and Policies      Technological Systems Feedback      Further discussion with drivers        Finally, conducting additional analysis on what causes tipping through interviews, surveys, additional data or FGD can be a viable step for the company.Thank you for your time reading!"
  },
  
  {
    "title": "üè† Real Estate House Sales - Tableau Dashboard",
    "url": "/posts/tableau-project/",
    "categories": "Tableau, Dashboard",
    "tags": "Tableau, Dashboard, Visualization",
    "date": "2023-11-23 00:00:00 +0800",
    





    
    "snippet": "Real Estate House Sales Dashboard (Tableau)Project Overview  The dashboard represents House Sales for King County, Washington and contains data on house details (sqft, floors, rooms, yrs), prices c...",
    "content": "Real Estate House Sales Dashboard (Tableau)Project Overview  The dashboard represents House Sales for King County, Washington and contains data on house details (sqft, floors, rooms, yrs), prices conditions and geodata (latitude/longitude, zipcode).  6 visualizations were created,          Daily House Sales Price (Line Chart)      House Price Distribution (Bar Plot)      Bedroom Count Distribution (Bar Plot)      Bathroom Count Distribution (Bar Plot)      View vs Condition (Heatmap)      Geodata Map        This is paired with interactive filters on:          Date      Year Built      Square foot Lot and Living      House Grade        This project is mostly based on familiarizing myself with the functions of tableau, however, it can be very helpful for buyers, and real estate sellers to have an overview of prices to expect depending on the property.  Viewers are able to see the prices of houses based on the year, size, rooms and location to get an idea of how to price their lots, or what prices to expect when purchasing properties.  Finally huge credits goes to ‚ÄúData With Mo‚Äù youtube channel for providing these and additional resources teaching Data Analytics. Despite the hands-on guide, I added additional functionality and edits (such as the map filter).Please access the full Tableau Dashboard here LINK.You can access the data used in XLSX format here LINK.Objectives  Create a dashboard that visualize changes in Home Sales Price by time, in relation to its traits (bedroom/bathroom count, year built, size) and locations.  Provide an overview of distribution of prices and rooms.  Visualize the condition and view of houses with its corresponding prices.  Create interactive filters for house buyers and sellers to know more about average house prices in accordance to their needs.Project ProcessProject Context  This project was specifically undertaken to fill in gaps in my knowledge of creating visuals after completing the Google Advanced Data Analytics Certificate.  Although the mentioned program went in depth in creating visualizations, I still felt the need to take more projects to familiarize myself further with tableau, as I have already done a dashboard in excel (see my excel dashboard here).  Although made in Tableau, I am also currently taking a PowerBi course (Story Telling with PowerBi - Coursera) and will update this portfolio website when more time is available.Steps Taken   Expand for full tableau creation process:  1. Loading of Data Set, Validating Data, Formatting      Data set was loaded in tableau. Fortunately, this dataset has already been cleaned and validated. This is a rarely the case in actual scenarios, but this is okay as the goal of this project is to learn tableau    Data types had to be properly validated/set each time they were dragged to columns and rows for the visuals.    Proper formatting had to be applied for each visual: font, colors, titles, lines and visualizations had to be uniformed.    2. Creation of Visuals      Visual 1 - Avg House Sales Price Line Chart: data types had to be validated and formatted.    Visual 2 - GeoData Map: proper country and zipcode had to be identified. Map was formatted for visibility.    Visual 3 - Distribution of House Prices: Proper identification of data types and formatting was applied. Tooltip fixed.    Visual 4 - Distribution of Bedrooms: formatting pasted from previous visuals. Renaming title and sheet.    Visual 5 - Distribution of Bathrooms: formatting was pasted and adjusting of content. Tooltip corrected.    Visual 6 - View vs Condition Heatmap: Dragging and reorganizing of variables, sorting fixed manually. Dragged price to color and labels. Formatted titles and visuals again.    3. Creation of Filters      Create calendar filter: drag calendar to col (weekday), rows (week) and filters (month/year). Drag price to color (avg), date to label (day) and format colors and columns.    Year filter: drag year to filters, show filter.    Sqft living/lot filter: drag sqft living/lot to filters, show filter.    4. Build the dashboard      Fixing sizing, set minimum to generic desktop size, uncheck maximum.    Drag necessary items: containers, text, object, filters, and rename titles.    Drag all visualizations and finalize formatting.    5. Filter functionality      The dashboard can be seen in the first sheet, while the second sheet contains instructions, input cells and calculations for the dashboard.    For future references and projects, this calculation sheet design can and should be improved. However, only the main visual was the focus during the task.    Applied filter by clicking:              More options &gt; apply to worksheets &gt; selected worksheets (select all).        Dashboard &gt; actions &gt; Filter &gt; edit &gt; untick map and line chart.        Do the same for the map to make it a filter.        Do the same for Yr, Sqft Loft and Sqft Living filters.              6. Final Check and Publishing      Final check up and formatting of text, numbers and relevant data.    Test sliders and filters.    The dashboard are saved and published via Tableau Public.  Conclusions and RecommendationsInsight  From May 2014 - 2015 (entire dataset), the highest distribution of houses had the following attributes:          Average Price of USD 500K      Average to Good Condition paired with Good to Excellent View      3-4 Bedrooms and 1-2 Bathrooms      Prices indicators:  Sqft living is the one of the highest indicators going beyond USD 1,000K when looking at the top half of largest sqft living.  ‚ÄúGrade‚Äù is also one of the highest indicators.          Grades 1-7 costs sits mostly USD 250K      At Grades 8 - 12, prices drastically jump to at average of USD 500-600K      Recommendations for House Shopping  For price sensitive buyers with budget around USD 250K, look at houses with grades from 1-7.  For those that want improved houses, it may be worth looking at lower grade houses and investing in renovation instead.  To make the most out of 300K budget, one can look  at houses built recently at 2000, and even look at grades 7-12. This seems to be the sweet spot for maximizing budget to house condition.  Despite the recommendations, shopping or selling for a house has lots of factors to account for, however, the dashboard is still able to give us an idea of appropriate pricings based on location.Improving the Project  Although the main purpose of this project to practice tableau was met, the following can be done to better the project:          Use more recent dates, or an API to gather up-to-date prices of homes.      For buyers and sellers, having a price filter will also be useful.      If data is available, additional attributes about the house can also be visualized.      With feature engineering, one can make a score rating of the amount of nearby establishments (schools, stores, offices) in relation to distance. This gives us a score for the locations which is especially beneficial for buyers and developers.            More thought on improving the visual can be put, however, this one retains good visibility and clarity.    Again you may access the full Tableau Dashboard here LINK.Thank you for your time viewing!"
  },
  
  {
    "title": "üìà Banking App Enrollment Campaign - Excel Dashboard",
    "url": "/posts/excel-project/",
    "categories": "Excel, Dashboard",
    "tags": "Excel, Dashboard, Visualization",
    "date": "2023-11-23 00:00:00 +0800",
    





    
    "snippet": "Enrollment Campaign for Banking App RegistrationProject Overview  A bank is launching a new campaign aimed to encourage current clients to enroll in their new mobile application.  The country is di...",
    "content": "Enrollment Campaign for Banking App RegistrationProject Overview  A bank is launching a new campaign aimed to encourage current clients to enroll in their new mobile application.  The country is divided into 5 regions. Performance for each region can be filtered using slicer function in excel.  A line graph, stacked bar chart and highlights of key values were used to represent key factors.  Data are inputted to a different sheet and values automatically update in the dashboard.You can access the EXCEL file here LINKObjectives  Visualize overall enrollment and performance for each region.  Compare registered and unregistered clients for each region.  Give information on campaign health via:          Current Enrollments vs Target      Total this Week and Remaining Clients      Days Left      Registered Clients (at 2.5M, at 2.5M and vs last week)      Project ProcessProject Context  This dashboard was given to me as a task for one of my internships, however, at that time I was not knowledgeable in the data field yet.  The task was to create a dashboard to track performance for the new mobile app enrollment campaign.  Due to data privacy, I was not provided with data, only examples from previous dashboards.Steps Taken1. Gathering of Relevant information  Available resources, tasks, references and relevant data was gathered in this step.  One of the most important resources I had was the reference to old dashboards due to the lack of data access as interns.2. Communication with relevant stakeholders  Despite the limited data access, my mentor at that time tasked me to create a format for the dashboard. I volunteered creating it via excel, including a backend sheet that automatically updates the dashboard based on values inputted.3. Creation of Data and Dashboard  Creating dummy data while considering if it can represent actual values was an important skill set in this case, as I had to understand how each value affects the overall data and visualization.  The dashboard can be seen in the first sheet, while the second sheet contains instructions, input cells and calculations for the dashboard.  For future references and projects, this calculation sheet design can and should be improved. However, only the main visual was the focus during the task.4. Dashboard and Visual DesignsVisual 1  The design and layout of the dashboard was created using canva. There were several drafts and iterations throughout designing but it was important to stick to the branding colors and visuals.  This was the visual used for the output with the logo removed.Visual 2  For the sake of the portfolio, I did slight edits of how I would approach the design. Despite this, I have kept the same functionality and visualizations.  The uploaded excel file will be using this visual.Conclusions and RecommendationsInsight  Although this visual used synthetic data, here are insights that can be gathered from the campaign:  The current registrations has kept up with the target registrations at the start but slowed down overtime.  South Metro Manila (SMM), North Metro Manila (NMM) and Visayas Mindanao (VISMIN) have the highest amount of registrations respectively whereas South Luzon (SL) has the highest growth versus last week.  All 5 divisions are growing at a steady rate. Performance dipped on week 5 for all divisions - in contrast to SL with a performance increase.          It is worth investigating what SL did during week 5 to increase registrations.      At 1.5Mn registrations, the number of clients registered was only 23% of the target set.      Performance improved and at 2.5Mn registrations, registered clients reached 76% of the target.      Although interpretation on this has to be clarified, compared to last week, current registration are still low only hitting 37% of the target registration.      Improving the Project  For future purposes, it will be ideal to link values from an SQL database to a visualization application such as Tableau or PowerBI.  However, if stakeholders or future users are more familiar with excel, excel is still very much a good option.  The visual was inspired by ‚Äòdark mode‚Äô, but in terms of accessibility, brighter takes will be easier to see.  If data was present, more filters/slicers to visualize results by date will be a great addition.  Feature engineering may also be also be applied to come up with new columns and further visualizations.Thank you for your time reading!"
  },
  
  {
    "title": "üßëüèª‚Äçü§ù‚ÄçüßëüèΩ HR Analysis: Predicting Employee Turnover with Machine Learning - Full Process",
    "url": "/posts/hr-analysis/",
    "categories": "Full Process, Data Science",
    "tags": "data science, cleaning, eda, visualization, logistic regression, decision tree, random forest, feature engineering, recommendations",
    "date": "2023-11-23 00:00:00 +0800",
    





    
    "snippet": "Image Source: peoplemanagingpeople.comData Science ProcessIn this project, the following skills were applied: Cleaning, EDA, Machine Learning Models (Logistic Regression, Decision Tree, Random Fore...",
    "content": "Image Source: peoplemanagingpeople.comData Science ProcessIn this project, the following skills were applied: Cleaning, EDA, Machine Learning Models (Logistic Regression, Decision Tree, Random Forest) and Recommendations  Please use the outline on the right side of the webpage for easier navigation!Project Objective Overview  Central Question: Why causes employees to leave the company?  We are tasked to understand the employee turn over in the company.  Based on this, we pull insights and strategical recommendations.  Libraries used include: numpy, pandas, matplotlib, seaborn, sklearn (logistic regression, decision tree, random forest, gridsearch, metrics) and pickle to save the model.  You can access the Jupyter Notebook IPYNB file here LINKProject Findings OverviewOn Employees who stayed:  Staying employees had an average of 3-4 projects assigned, rendering monthly hours of 150-255 (still high compared to average of 167hrs)  Satisfaction levels were generally high but lowered for tenure/years 5-6.On Employees who left:  Employees are generally overworked with almost double the regular monthly hours.  Those who left either worked less hours and had only 2 projects assigned OR  Are overworked with 255 - 300+ hours and had had more projects (4-7 projs assigned).  Everyone with 7 projects assigned left.  Highly satisfied employees, with more than 5 years are leaving due to lack of promotion and salary increase.  Those with 4 years in the company, may have left due to drastic policy change.On Regression and Machine Learning Models:  The logistic regression model approach achieved high scores (79% precision, 82% recall, and f1 of 80%).  The decision tree model and random forest had even better scores and performed similarly (94% precision, 91% recall, f1 of 93%, accuracy and auc 98%).  Feature Engineering was used to drop data which will not be realistically available.  Second round of tree models were created. The random forest is the champion model and scored very well on the test set: (87% precision, 91% recall, 89% f1, accuracy 96% and auc 94%)Recommendations at the end!Data Cleaning and PreparationAfter importing the packages we can do our initial data cleaning  head(), .info, .describe and .columns to better understand our data  rename the columns to snake_case (lowercase and underscores) and correct mispellings  .isnull(), .duplicated(), .drop_duplicates() to check for missing values and duplicates  boxplot to check for outliersWe use Interquantile Range to identify the outliers. Fortunately there were no null values, however, there were about 3000 duplicates and 824 outliers in the tenure section. There are no major ethical considerations at this stage however we need to consider whether or not to remove outliers.EDA and VisualizationUsing the .value_counts(normalize=True) function, we can see the ratio of leavers. 1991(17%) left and 10000(83%) stayed.Data VisualizationsFirst, we use a stacked boxplot from the seaborn library to show the average monthly hours, compared to number of projects. We used stacked to visualize those who left (marked as 1) and those stayed (marked 2).1. Monthly Hours by Number of Projects (Stacked Box plot)From here we can observe that leavers fall into certain groups ff:Group A:  Assigned only 1-2 projects, this has the highest amount of leaves. These group worked significantly less hours than peers.  It is possible these were fired due to lack of hours, or were assigned less since they have filed LOA, vacation or leave notices.Group B:  Assigned 4-7 projects, as projects increase, so does monthly hours, and leaves.  Everyone assigned 7 projects left.  Worked significantly more hours and are overworked.  Worked 255 - 295 hours for a month. Double the usual amount of 166 hours (8 hrs, 5x a week, 4x a month).Stayed Group:  Assigned 3-4 projects, working 150 - 255 hours, had the highest amount of stays.  Compared to the average 166 hours, this group still works a significant amount of hours.2. Monthly Hours and Satisfaction level (Scatter Plot)  This scatter plot examines average monthly hours and satisfaction levels.  The dotted red line shows us a reference point of an average 166 hours for the average employee hours.  Notice how leavers (in orange) are clumped in certain areas of the scatter plot. This backs up our observation on Group A and Group B as mentioned earlier.  Group C: Looking at the top right of the plot, we notice a third group not evident in the first box plot.          This group has high satisfaction (0.8) but paired with high work hours (225-275), ended up leaving.        Note that we also see a strange shape of distribution, showing signs of synthetic data as distributions are not evenly distributed but instead are clumped up. They are also skewed to the right.3. Satisfaction by Tenure (Stacked Box plot)Let‚Äôs continue using our grouping system to make general observations. We can compile them later. From this visual we can observe the ff:  2 years had generally low satisfaction (Group D)  3 years had low satisfaction and highest leaves (Group D)  4 years has set of dissatisfied employees who left (Group F)  5-6 years had high satisfaction, but left (Group E)Employees who left fell into two categories:  Group D. Dissatisfied with lower tenures and  Group E. Very satisfied with medium to higher tenures.          Further investigation should be done. Why did the employees leave despite a high amount of satisfaction?      It is possible that although they enjoyed their work, lack of promotions or salary increase caused them to leave.        Group F. 4 Year tenure, with very low satisfaction.          It is worth investigating further that led to very low dissatisfaction levels. Did this group face major changes in policies or salaries?        Satisfaction levels of year 7-10 and new employees are similar. Looking into which reasons led them to stay will be valuable.A closer look will be applied for Group E as it is questionable why they left despite high satisfaction.4. Group E: Employee and Salary Distribution (Pie Chart)  To analyze this we filtered the group by satisfaction level of 7 or more, tenure of more than 5 and left the company.  Despite being in the company for 7+ years, only 2% had high salaries. 58% have low salaries, and the rest are in medium.      28% are in sales, 19% in IT and 17% in support. Only 1 person was promoted.    Despite the high satisfaction, leaves may be caused by lack of promotion and increase in salary despite the amount of years in the company.5. Mean and Median Analysis on Leaves and Stays (Table)  We use this code block to show a table depicting the mean and median satisfaction of employees who left and stayed:# Calculate mean and median satisfaction scores of left and stayeddf1.groupby(['left'])['satisfaction_level'].agg([np.mean,np.median])            ¬†      Mean      Median                  Left      0.677      0.69              Stayed      0.440      0.41      For those who stayed (Mean &lt; Median):  Distribution is negatively skewed  There are more extreme scores (dissatisfied) in the bottom than at the top (satisfied)  The majority are only moderately satisfied, but there is a small number very dissatisfied pulling down the mean.  The company may have a polarized environment - meaning there are very satisfied and very dissatisfied workforceFor those who left (Mean &gt; Median):  The most dissatisfied employees are more likely to leave, the company looses its unhappiest employees, improving overall satisfaction in remaining, this may be a flag of high turn over rates.  There are root issues not addressed leaving to more leaves.6. Salary Histogram by Tenure (Short and Long, Histogram)  As years increase, the salary does not increase proportionally.  Longer years did not necessarily convert to higher salary.  For those that are paid high salaries, they have stayed in the company for more than 10 years. This may refer to C-level managers.7. Monthly hours by evaluation score (Scatter Plot)  Leavers (orange) are observed in the lower left and upper right of the plot.  Two leave groups can be found again:          High monthly hours and received high evaluation      Less time below the average monthly hours and received low evaluation        Working long hours does not guarantee high evaluation score since evaluation is still distributed randomly across increasing hours  Again, large majority of employees work more than 167 hours a month.8. Monthly hours by promotion (Past 5 years, Scatter Plot)The plot informs us the following:  The top part shows those who received promotions. Those below did not.  The proportion of promoted in the last 5 years were small in relation to the amount of employees.  Most of those who left were from those not promoted, despite working the longest hours.9. Employee Leaves by Department (Histogram)  No department in particular has a proportionally amount who stayed or left.  Although, sales, technical and support has the highest amount who left - this is balanced by the fact that there are more employees as well.10. Variable Correlation (Heatmap)The highest positive correlation includes:  Number of projects and average monthly hours  Last evaluation and number of projects  Last evaluation and average monthly hoursThe highest negative correlation includes:  satisfaction level and employees leftEDA Insight Summary!Various observations can be said through our eda, we found that leaving is related with:  longer working hours  increasing amount of projects  lower satisfaction levels  lack of promotion  lack of increase in salary throughout years.Working long hours, but not receiving promotions, higher salary, or better evaluation scores may have caused dissatisfaction and burn out. Despite this, people who have stayed for more than 6 years tend to stay.   Expand for additional insights:  To decrease confusion of our alphabetical groupings, we will compile them into 4 main categories of ‚ÄúChurned‚Äù.  Churned 1 includes:      Group A: Significantly worked less hours with only 2 projects assigned    Group D: dissatisfied and with lower tenure, 3 years and below    This subgroup have lower tenures, worked less hours and had less projects assigned.    Churned 2 includes:      Group B: Significantly more hours worked and more projects assigned    Everyone with 7 projects assigned left    This subgroup may have been exposed to overwork or experienced burnout.    Churned 3 includes:      Group C: High satisfaction, but very significant amount of work hours 225 - 275.    Group E: High satisfaction, with higher tenure (more than 5 years) but still left    This subgroup may have left due to lack in promotion and salary increase.    Churned 4 includes:      Group F: 4 Year tenure with very low satisfaction    This subgroup may have experienced impactful changes.    Further investigation of changes in policies required.    Stayed:      For the groups who stayed, there was an average of 3-4 projects assigned.    High monthly hours of 150-255 hours, from the average 166.7    Satisfaction level ranges were relatively high for tenures 2-4, lowered for tenures 5-6, then returned to the initial ranges for 7 and above years.  Model Building A - Logistic Regression  üß™ üìàThe following is a concise outline of steps taken, however, we will not be going into detail.Again, feel free to visit the jupyter notebook for step by step information here LINK   Expand for Steps Taken:      Encode non-numeric variables (via pd.get_dummies function)    Correlation Heatmap    Employees Left / Stayed across Depts.    Remove outliers    Feature Selection    Test, train split    Fitting the model    Confusion Matrix    Checking class balance    Evaluation of Metrics  Logistic Regression Model EvaluationTo evaluate a model we can use a Confusion Matrix to show us the amount of True Positives/Negatives and False Positives/NegativesCorrect Predictions:  Top Left: True Positives - Predicted leaving and actually left.  Lower Right: True Negatives - Predicted staying and actually stayed.False Predictions:  Top Right: False Positives - Predicted leaving but stayed  Lower Left: False Negatives - Predicted staying but left.What this means  The model was able to correctly predict the majority of employees leaving (2165).  The next largest quadrant is False Negatives, meaning the model predicted leavers, who actually stayed.  This means that our model has a little bit of overfitting, as it is sensitive to factors that would make employees leave, this is good since the model is  sensitive to employee that has potential to leave.Scoring  With 83% and 17% split, the balance is not perfect, but not too imbalanced also, this may have cause the slight overfit.      Due to this accuracy is not a good metric, but we can use precision, recall, f1 and support.    The logistic regression achieved a precision of 79%, recall of 82%, and f1 of 80%.Model Building B - Decision Tree and Random Forest ‚öóÔ∏èüèïÔ∏èThe following is a outline of steps taken throughout the Decision Tree modeling. For full steps visit the jupyter notebook here LINK  Isolate Dependent Variables  Select Features  Test Training SplitDecision Tree 1 üå≤   Expand for Steps Taken      Instantiate, Params, Scoring and GridSearch    Fit Model    Best Params and AUC    Extract Scores  Scores:  92% Precision, 92% recall, 92% F1, 97% accuracy and auc.  All scores are past 90% which are VERY strong indicators of a good model.  We will also build a random forest to reduce overfitting, and grid search for the best parameters.Random Forest 1 üèïÔ∏è   Expand for Steps Taken      Instantiate, Params, Scoring and GridSearch    Fit Decision tree model to training data    Save model via Pickle    Best Params, AUC and Evaluate Scores    Get all scores    Pickle to save model training time  Scores:  This model performed outperformed the decision tree model.          95% Precision, 92% recall, 93% F1, 98% accuracy and auc.        As the better model, let‚Äôs use our test set here. Our test set is a portion of the data that we hide, so we can use it to evaluate our model after training it.  Test set scoring:          96% Precision, 92% recall, 94% F1, 98% accuracy and 96% auc.      Our model performed even better in the test set.      We can be confident that the model will perform well on unseen data.      Feature Engineering for 2nd round of Modeling  Our evaluation scores seem to high and may be cause by data leakage.  This happens when we use data which may:          Already exist in test data      Realistically, we may not have access to this data during deployment        During HR‚Äôs daily operations, we may not have immediate access to satisfaction levels.  Average monthly hours may also be too correlated if employees already gave a resignation notice.  Lets apply the ff:          Satisfaction level column is removed      New column ‚Äòoverworked‚Äô will be either 1 (for 175 hrs+ rendered) or 0 (less than 175 hrs).      Isolate new variables      Create test, train split.      Decision Tree 2 üå≤üå≤Based on our new features, let‚Äôs create a second decision tree.   Expand for Steps Taken      Instantiate, Params, Scoring and Grid Search    Fit model to values    Best Params, Best scores  Scores:  The model has great performance despite dropping satisfaction levels and detailed work hours.            model      precision      recall      F1      accuracy      auc                  Decision Tree 1 CV      91.46%      91.69%      91.57%      97.20%      96.98%              Decision Tree 2 CV      85.67%      90.36%      87.89%      95.85%      95.94%      Random Forest 2 üèïÔ∏èüèïÔ∏èWe will also create a 2nd random forest based on our new features.   Expand for Steps Taken      Instantiate, Params, Scoring and Grid Search    Fit model to values    Pickle    Best Params, Best scores, make results    Confusion Matrix  Scores:  As expected, scores lowered with dropped values, however model still works great.            model      precision      recall      F1      accuracy      auc                  Decision Tree 1 CV      91.46%      91.69%      91.57%      97.20%      96.98%              Random Forest 1 CV      94.87%      91.56%      93.18%      97.78%      98.04%              Decision Tree 2 CV      85.67%      90.36%      87.89%      95.85%      95.94%              Random Forest 2 CV      86.64%      88.08%      87.32%      95.76%      96.49%        If AUC is our deciding matrix, random forest 2 performed better.          AUC is useful in our situation some with class imbalance      It is also a good metric when comparing ranking different models.      Random forest 2 is our champion model üëë      Lets evaluate the model with our test set and create a confusion matrix.            model      precision      recall      F1      accuracy      auc                  Random Forest 2 CV      87.12%      90.96%      89.00%      96.26%      94.14%      Recall that:  Top Left: True Positives - Predicted leaving and actually left.  Lower Right: True Negatives - Predicted staying and actually stayed.  Top Right: False Positives - Predicted leaving but stayed  Lower Left: False Negatives - Predicted staying but left.  The model was able to correctly predict the majority of employees leaving (2433).  The next largest quadrant is the True Negatives, meaning the model predicted stays successfully.  Since our model predicted more false positives than false negatives, it is likely to predict leavers, who actually stay. This is good since our model is sensitive to leavers.  Compared to our Linear regression model, this has significantly better performance.Decision Tree Splits and Feature ImportancesThis graph shows the decision tree splits, although a bit cluttered, we can use Feature Importances with a barplot to see which variables were most important in prediction.Decision Tree: Feature Importances for Employee Leaving PredictionRandom Forest: Feature Importances for Employee Leaving PredictionWe can see that he most important predictors on leavers are:  Number of Projects assigned  Last Evaluation (Ranked first in Decision Tree)  Tenure  OverworkedWhat this means:  Although further investigation is needed, we see that the last evaluation is one of the top predictors.          This means that employees are severely impacted by their performance review, or      Low performance reviews eventually lead to leaving:                  whether by resignation, firing, lower pay or other factors.                      Number of projects assigned and overwork are also both top predictors, our earlier findings our supported.  Finally tenure is also one of the most important predictors.          It is important to conduct interviews or follow-up investigation on the groups of individuals that left the company (such as year 4 leavers).      Recommendations and Next Steps for Salifort Motors   Expand for Full Summary/Recap in earlier stages  Insights Based on Model  Findings from EDA  Leaving is related to:      longer working hours    increasing amount of projects    lower satisfaction levels    lack of promotion    lack of increase in salary throughout years    The leavers fall into the ff groups:      Worked less hours and only 2 projects assigned, lower tenures 3 and below    Worked more hours and more projects assigned, (7+ assigned all left)    High satisfaction, but high amount of work hours, lack of promotion or salary increase    Tenure of 4 years, may have experienced impactful changes.    Here are the attributes of those who stayed:      Average of 3-4 projects assigned    Monthly hours rendered 150-255    High satisfaction for tenure 2-4, lower for 5-6 and reaches initial ranges 7 on above.    Findings from Modeling  From the importance features the ff were identified as top leaving predictors:      Number of Projects assigned    Last Evaluation    Tenure    Overworked  Recommendations on Workload  Equally distribute workload between workers, (between 3-4 projects only).  Reduce monthly hours rendered, through automation, improved systems or workflow as overwork is highly correlated to leaves.  Conducting interviews on most time consuming areas of the work will be a huge step.  Make sure new employees understand hourly expectations before hiring.  Reward employees working overtime via pay, benefits or bonus.Recommendations on Evaluation  Identify effect of low evaluation to employed and quitting, is pay reduced? Does this eventually lead to firing?  Avoid reserving high evaluation for 200+ hrs rendered, consider a bonus or incentive system instead.  Utilize the model to predict potential leavers, and create an intervention and reward program for employees.Recommendations on Identifying Causes  Identify via interviews or investigation, what causes lower satisfaction on tenures 5-6, and what caused leaving from year 4.  Consider promoting or increasing salary for individuals on their 4th year (ensure promotion within 5 years).  Conduct internal surveys, FGDs and team meetings to check on employees workload, health, mental and well-being.Improving the Model  Reduce columns of data that will not be realistically always available (such as last evaluation if not conducted often).  Creating unsupervised learning models to identify common traits between employees and leaving.  Specific information instead of categorical (such as salaries) and see if it improves performance.  Test different models or utilize models with better explainability (such the single decision tree) to better identify reasons for leaving.Other Questions that can be addressed  Departments with highest leaves include sales, technical and support, however, this is in proportion as these groups are the largest also.  For further insights or analyses, feel free to contact me.Resources Used  Previous work materials  Google Advanced Data Analytics Certificate course materialsEthical Considerations  Deployment of the model will cause identification of certain individuals who may be likely to resign. With this, the company has great responsibility to maintain fairness when treating its leaving and non-leaving employees. Likewise, the model still has false positive/negative predictions and ultimately, early intervention is required from the company rather than relying on the model.ConclusionThank you for your time reading this output on Salifort Motors. Although the output was lengthy and insights are summarized at the end, more detailed information and analyses are provided throughout the notebook, specifically in the Exploratory Data Analysis (EDA) and model building.If you want similar analysis or have job opportunities for a Data Analyst/Scientist feel free to email me at lotillaryan@gmail.com. Thank you again for your time and have a great day ahead!"
  },
  
  {
    "title": "Hello World",
    "url": "/posts/hello-world/",
    "categories": "Hello World",
    "tags": "Hello World",
    "date": "2023-06-03 00:00:00 +0800",
    





    
    "snippet": "Hello WorldHello World this is my personal blog.",
    "content": "Hello WorldHello World this is my personal blog."
  }
  
]

